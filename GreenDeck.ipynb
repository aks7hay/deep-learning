{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1RZBdNCTxLuDgEKd8ceJ8eEJ2fY_Nxm7C",
      "authorship_tag": "ABX9TyMWKM0OQfwM3LAbz4CS5qvu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAqwuTwaOOYt"
      },
      "source": [
        "# Greendeck Machine Learning Assignment\n",
        "\n",
        "Akshay Kumar Prasad\n",
        "\n",
        "Contact email id : akshayprasad885@gmail.com\n",
        "\n",
        "Phone number : 8409787345\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOuG-3xNhg0K"
      },
      "source": [
        "# Multi-model learning for Image and Text Semantic classification\n",
        "\n",
        "Model used for Text analysis : word2vec\n",
        "\n",
        "Model used for Image  analysis : Transfer Learning - VGGNet16\n",
        "\n",
        "\n",
        "Brief Introduction about the Dataset and Problem:\n",
        "\n",
        "1) The Dataset csv \"training_data.csv\" consists of 65714 products accompanied along with its image name, text and class name.\n",
        "\n",
        "2) images.zip folder contains all the images mentioned in \"training_data.csv\" under the image column\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvSrmDgSw9Ea"
      },
      "source": [
        "I have break down 65714 images into two parts: 75% in train images(49,267 Files in 48 Folders according to their classes) and 25% in test images(16,447 Files in 48 Folders according to their classes) for further model building."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGS1dLQ3yFF7"
      },
      "source": [
        "# This separating part of the code I have done in my local system. \n",
        "\n",
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Reading data from file\n",
        "data = pd.read_csv(\"training.csv\")\n",
        "# Grouping by class and image and Converting that to dataframe\n",
        "dataf = pd.DataFrame(data.groupby(\"classes\")[\"image\"].unique())\n",
        "# Creating list of 48 folder and their respective product\n",
        "folder = []\n",
        "for i in dataf.index:\n",
        "    folder.append(i)\n",
        "product = []\n",
        "for j in range(len(folder)):\n",
        "    for i in dataf.iloc[j]:\n",
        "        product.append(i)\n",
        "\n",
        "# Separating train and test files. Train file: having train image and test file having test images\n",
        "train = []\n",
        "test = []\n",
        "for i in range(len(product)):\n",
        "    train.append(list(product[i][0:int(len(product[i])*0.75)]))\n",
        "    test.append(list(product[i][int(len(product[i])*0.75):]))\n",
        "\n",
        "# Separating csv file to train file\n",
        "train_data = []\n",
        "for i in train:\n",
        "    for j in i:\n",
        "        train_data.append(data.iloc[data[\"image\"].values == j].index)\n",
        "training = data.iloc[[train_data[i][0] for i in range(len(train_data))]]   \n",
        "training.to_csv(r\"D:\\Data Science\\Hackathon\\Greendeck\\train.csv\")\n",
        "\n",
        "# Separating csv file to test file\n",
        "test_data = []\n",
        "for i in test:\n",
        "    for j in i:\n",
        "        test_data.append(data.iloc[data[\"image\"].values == j].index)\n",
        "testing = data.iloc[[test_data[i][0] for i in range(len(test_data))]]   \n",
        "testing.to_csv(r\"D:\\Data Science\\Hackathon\\Greendeck\\test.csv\")\n",
        "\n",
        "# Creating folders for different commodities\n",
        "folders = []\n",
        "for i in range(len(dataf.index)):\n",
        "    folders.append(list(dataf.index[i].split(\"<\")[1:]))\n",
        "#7. Creating path of different folder in train dataset created above\n",
        "paths_train = []\n",
        "path_train = \"D:/Data Science/Hackathon/Greendeck/items/train/\"\n",
        "\n",
        "for i in range(len(dataf.index)):\n",
        "    paths_train.append(path_train+folders[i][0]+\"_\"+folders[i][1]+\"/\") \n",
        "\n",
        "# Creating path of different folder in test dataset created above\n",
        "paths_test = []\n",
        "path_test = \"D:/Data Science/Hackathon/Greendeck/items/test/\"\n",
        "\n",
        "for i in range(len(dataf.index)):\n",
        "    paths_test.append(path_test+folders[i][0]+\"_\"+folders[i][1]+\"/\") \n",
        "\n",
        "    \n",
        "# Creating directories in local system for train\n",
        "for i in range(len(paths_train)):\n",
        "    try:\n",
        "        os.mkdir(paths_train[i])\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % path_train)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % path_train)  \n",
        "        \n",
        "# Creating directories in local system for test \n",
        "for i in range(len(paths_test)):\n",
        "    try:\n",
        "        os.mkdir(paths_test[i])\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % path_test)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % path_test)         \n",
        "\n",
        "# For moving file from source to train folder\n",
        "n = 0\n",
        "while n <= 47:\n",
        "    \n",
        "    # Source file : Ready\n",
        "    source_train = []\n",
        "    destiny_train = []\n",
        "    for j in train[n]:\n",
        "        source_train.append(paths_train[n]+j)\n",
        "\n",
        "    # Destination file : ready\n",
        "    for i in range(len(train[n])):\n",
        "        destiny_train.append(paths_train[n]+train[n][i])\n",
        "\n",
        "    # moving\n",
        "    for i in range(len(source)):\n",
        "        shutil.move(source_train[i], destiny_train[i])\n",
        "    n = n+1\n",
        "\n",
        "    \n",
        "\n",
        "# For moving file from source to test folder\n",
        "n = 0\n",
        "while n <= 47:\n",
        "    \n",
        "    # Source file : Ready\n",
        "    source_test = []\n",
        "    destiny_test = []\n",
        "    for j in test[n]:\n",
        "        source_test.append(paths_test[n]+j)\n",
        "\n",
        "    # Destination file : ready\n",
        "    for i in range(len(test[n])):\n",
        "        destiny_test.append(paths_test[n]+test[n][i])\n",
        "\n",
        "    # moving\n",
        "    for i in range(len(source)):\n",
        "        shutil.move(source_test[i], destiny_test[i])\n",
        "    n = n+1\n",
        "\n",
        "\n",
        "   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL2edlj12r2w"
      },
      "source": [
        "# PART 1\n",
        "\n",
        "Importing important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqLzAuz5hWts",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "4c10c303-834f-49e8-ce59-931d565a1dfc"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from os import listdir\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from string import punctuation\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import models\n",
        "from keras.applications import VGG16\n",
        "import nltk\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZU_fUpF23OH"
      },
      "source": [
        "Mounting Google Drive to read files saved in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vB_B-bW6Ejr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d0bcf8e-160c-4b74-c45a-4ccb741ad984"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBkxTGYpIkHv"
      },
      "source": [
        "# Text  Embeddings Input Model (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAJ4msAA3Gcw"
      },
      "source": [
        "1.Reading training.csv files from google drive \n",
        "\n",
        "2.Setting the index to classes column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQKd7HOoobWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "acd95ddf-97cf-40e4-88ad-6ec76564ce97"
      },
      "source": [
        "df =  pd.read_csv('/content/gdrive/My Drive/HUSE/training.csv')\n",
        "df.set_index(['classes'], inplace = True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>classes</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>beauty&lt;makeup&lt;eyeshadow</th>\n",
              "      <td>5da821eb7f3e301b4504bb4a_0.jpg</td>\n",
              "      <td>Marc Jacobs Beauty  Eye-Conic Longwear Eyeshad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beauty&lt;makeup&lt;eyeshadow</th>\n",
              "      <td>5da81cde7861c2af6a5a88cf_0.jpg</td>\n",
              "      <td>Marc Jacobs Beauty  Eye-Conic Longwear Eyeshad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;knitwear&lt;fine knit</th>\n",
              "      <td>5da8219a6504fb65da0050aa_0.jpg</td>\n",
              "      <td>Prada  Wool sweater</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;pants&lt;straight leg</th>\n",
              "      <td>5da821856504fb65cea703cf_0.jpg</td>\n",
              "      <td>Prada  Printed silk-satin twill straight-leg p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;pants&lt;straight leg</th>\n",
              "      <td>5da82200b25b035d1d17bec6_0.jpg</td>\n",
              "      <td>Prada  Cropped chain-trimmed printed crepe str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beauty&lt;makeup&lt;lipstick</th>\n",
              "      <td>5da817b06504fb65d41c5455_7.jpg</td>\n",
              "      <td>Illamasqua  Lipstick - Climax</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bags&lt;tote bags&lt;tote bags</th>\n",
              "      <td>5da81f6f6504fb65c4de4009_7.jpg</td>\n",
              "      <td>Chloé  Marcie medium textured-leather shoulder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bags&lt;shoulder bags&lt;shoulder bags</th>\n",
              "      <td>5da81fa5465e00845f490bc4_7.jpg</td>\n",
              "      <td>Gucci  Sylvie mini leather-trimmed calf hair s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beauty&lt;makeup&lt;lipgloss</th>\n",
              "      <td>5da8214eb25b035d1d17b3b4_7.jpg</td>\n",
              "      <td>Marc Jacobs Beauty  Enamored Hi-Shine Lip Lacq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;dresses&lt;gowns</th>\n",
              "      <td>5da8221d6504fb65da005afa_7.jpg</td>\n",
              "      <td>Halfpenny London  Luella organza-trimmed satin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65714 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                           image                                               name\n",
              "classes                                                                                                            \n",
              "beauty<makeup<eyeshadow           5da821eb7f3e301b4504bb4a_0.jpg  Marc Jacobs Beauty  Eye-Conic Longwear Eyeshad...\n",
              "beauty<makeup<eyeshadow           5da81cde7861c2af6a5a88cf_0.jpg  Marc Jacobs Beauty  Eye-Conic Longwear Eyeshad...\n",
              "clothing<knitwear<fine knit       5da8219a6504fb65da0050aa_0.jpg                             Prada  Wool sweater   \n",
              "clothing<pants<straight leg       5da821856504fb65cea703cf_0.jpg  Prada  Printed silk-satin twill straight-leg p...\n",
              "clothing<pants<straight leg       5da82200b25b035d1d17bec6_0.jpg  Prada  Cropped chain-trimmed printed crepe str...\n",
              "...                                                          ...                                                ...\n",
              "beauty<makeup<lipstick            5da817b06504fb65d41c5455_7.jpg                    Illamasqua  Lipstick - Climax  \n",
              "bags<tote bags<tote bags          5da81f6f6504fb65c4de4009_7.jpg  Chloé  Marcie medium textured-leather shoulder...\n",
              "bags<shoulder bags<shoulder bags  5da81fa5465e00845f490bc4_7.jpg  Gucci  Sylvie mini leather-trimmed calf hair s...\n",
              "beauty<makeup<lipgloss            5da8214eb25b035d1d17b3b4_7.jpg  Marc Jacobs Beauty  Enamored Hi-Shine Lip Lacq...\n",
              "clothing<dresses<gowns            5da8221d6504fb65da005afa_7.jpg  Halfpenny London  Luella organza-trimmed satin...\n",
              "\n",
              "[65714 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmOukwaL3gbu"
      },
      "source": [
        "Since, the size of data is huge, we are using only some part of it for the ease of model implementation only. Same logic will be applied on whole dataset later for full training purpose.\n",
        "\n",
        "\"Long coats\", \"casual jackets\", \"fine knitwear\" from clothing section and \"necklace\" from jewelary and watches section has been randomly chosen for model training and stored in dataframe \"df1\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_k59mkV3Sn4"
      },
      "source": [
        "df1 = df.loc[['clothing<coats<long','jewelry and watches<fine jewelry<necklaces','clothing<jackets<casual jackets','clothing<knitwear<fine knit']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msS8J4jv4hK_"
      },
      "source": [
        "#### Brief Inroduction about word2vec word embedding model\n",
        "word2vec is one of the word embedding model developed by Google pre-trained on Google News. It represent a word in 300 different dimensions or vector forms. It is a shallow two-layer neural net that processes text by “vectorizing” words. Its input is a text corpus and its output is a set of vectors: feature vectors that represent words in that corpus. While Word2vec is not a deep neural network, it turns text into a numerical form that deep neural networks can understand.\n",
        "\n",
        "Word2vec is a computationally efficient predictive model for learning word embeddings from raw text. If we put any raw text on word2vec model and get a embedding on the particular word we will get 300 dimensional vectors forming a dense matrix as opposed to sparse matrix created in Document term matrix. This pretrained model help us in getting a vector representation of our word without any training on local system.\n",
        "\n",
        "Word2vec allow us to perform linear operations on words. Words can be subtracted or added using linear operation. \n",
        "\n",
        "The word embedding approach is able to capture multiple different degrees of similarity between words. Pattern like word \"King\" is to word \"Queen\" is similar to word \"Man\" is to word \"Women\". This similarity is calculated by the cosine distance between vector representation of two words. Hence, capturing their semantic relationship. Similar words have similar vector representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edlNJdYi5zct"
      },
      "source": [
        "\n",
        "\n",
        "Word Embedding is a collective name for those techniques where words are translated into dense low dimensional vectors.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEkdSLxSGMkI"
      },
      "source": [
        "Embedding file is downloaded from the given source file as under and stored in \"EMBEDDING_FILE\" variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYBTy8SWsJ3J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c8fe8496-49cb-4af7-80c0-b723924b957b"
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz'\n",
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-01 19:40:31--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.15.150\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.15.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcgSin0ZFVvC"
      },
      "source": [
        "The training is streamed, meaning sentences can be a generator, reading input data from disk on-the-fly, without loading the entire corpus into RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3L3n1GThWns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6b3a7da8-c761-44b0-93fb-3cdbb1e1e1b4"
      },
      "source": [
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypYExtYsIe5v"
      },
      "source": [
        "Permanently resetting the index to classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsLIuMsX82QL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c6619a1b-5157-4089-e3a7-5475ac25a00c"
      },
      "source": [
        "df1.reset_index(inplace= True)\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>image</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da82235b25b035d1d17c108_0.jpg</td>\n",
              "      <td>Ann Demeulemeester  Convertible belted satin c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821b16504fb65da005330_0.jpg</td>\n",
              "      <td>Prada  Belted wool-twill coat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821d3b25b035d1d17bbe7_0.jpg</td>\n",
              "      <td>Gucci  Grosgrain-trimmed wool-blend bouclé coat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821216504fb65da004828_0.jpg</td>\n",
              "      <td>Gucci  Leather-trimmed belted cotton-blend can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821cdb25b035d1d17bb5b_0.jpg</td>\n",
              "      <td>Danielle Frankel  Jean silk and wool-blend sat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               classes  ...                                               name\n",
              "0  clothing<coats<long  ...  Ann Demeulemeester  Convertible belted satin c...\n",
              "1  clothing<coats<long  ...                    Prada  Belted wool-twill coat  \n",
              "2  clothing<coats<long  ...  Gucci  Grosgrain-trimmed wool-blend bouclé coat  \n",
              "3  clothing<coats<long  ...  Gucci  Leather-trimmed belted cotton-blend can...\n",
              "4  clothing<coats<long  ...  Danielle Frankel  Jean silk and wool-blend sat...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQx-xVMII5xu"
      },
      "source": [
        "Creating user defined function for text cleaning:\n",
        "\n",
        "1)  tokens = word_tokenize(re.sub('[^a-z ]',' ', sent.lower())) : First it will convert every word into lower case and then substitute all the non-alphabetical characters with a space. There are some instances in the text where characters like \"-\" are present. It will remove it with a space and then tokenise the words.\n",
        "\n",
        "2) stop_updated  = stopwords.words(\"english\") + list(punctuation) : Creating a list of english stopwords and adding punctuation \n",
        "\n",
        "3) text = [term for term in tokens if term not in stop_updated and len(term)>2]\n",
        "  res = \" \".join(text) : Now my raw text will be words that are tokenised but not are stopwards and its length is more than 2. Every word in the tokenised list will be joined using space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS7zgGUsflno"
      },
      "source": [
        "def clean_text(sent):\n",
        "    tokens = word_tokenize(re.sub('[^a-z ]',' ', sent.lower()))\n",
        "    stop_updated  = stopwords.words(\"english\") + list(punctuation) \n",
        "    text = [term for term in tokens if term not in stop_updated and len(term)>2]\n",
        "    res = \" \".join(text)\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k7xRQrnSTBh"
      },
      "source": [
        "Applying the user defined fucntion on name column of the dataframe. End result will be as described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8j_-i6eflqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "339361d0-efbe-4b60-9778-c5304a46c376"
      },
      "source": [
        "df1[\"clean_name\"] = df1.name.apply(clean_text)\n",
        "df1.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4165, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ-J19vAwrq3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "80b0ee28-7fc9-44e7-f4fe-0dcf84d608ae"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>image</th>\n",
              "      <th>name</th>\n",
              "      <th>clean_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da82235b25b035d1d17c108_0.jpg</td>\n",
              "      <td>Ann Demeulemeester  Convertible belted satin c...</td>\n",
              "      <td>ann demeulemeester convertible belted satin coat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821b16504fb65da005330_0.jpg</td>\n",
              "      <td>Prada  Belted wool-twill coat</td>\n",
              "      <td>prada belted wool twill coat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821d3b25b035d1d17bbe7_0.jpg</td>\n",
              "      <td>Gucci  Grosgrain-trimmed wool-blend bouclé coat</td>\n",
              "      <td>gucci grosgrain trimmed wool blend boucl coat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821216504fb65da004828_0.jpg</td>\n",
              "      <td>Gucci  Leather-trimmed belted cotton-blend can...</td>\n",
              "      <td>gucci leather trimmed belted cotton blend canv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clothing&lt;coats&lt;long</td>\n",
              "      <td>5da821cdb25b035d1d17bb5b_0.jpg</td>\n",
              "      <td>Danielle Frankel  Jean silk and wool-blend sat...</td>\n",
              "      <td>danielle frankel jean silk wool blend satin coat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               classes  ...                                         clean_name\n",
              "0  clothing<coats<long  ...   ann demeulemeester convertible belted satin coat\n",
              "1  clothing<coats<long  ...                       prada belted wool twill coat\n",
              "2  clothing<coats<long  ...      gucci grosgrain trimmed wool blend boucl coat\n",
              "3  clothing<coats<long  ...  gucci leather trimmed belted cotton blend canv...\n",
              "4  clothing<coats<long  ...   danielle frankel jean silk wool blend satin coat\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICZsn1u43Kmp"
      },
      "source": [
        "Every word in \"clean_name\" column is tokenised.Then all the words in a document is joined and append to list \"texts\". Then on these texts sequences is created using word index. That means every unique word is assigned a unique number. Since, the length of every document is diffferent, hence we need to equalise them by Padding them at the end of each document sequence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyjvlOWjy2WY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9a00bbc-8f12-4096-87c5-1c5d29a437b2"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "texts = []\n",
        "for tag_list in df1['clean_name']:\n",
        "    texts.append(''.join(tag_list))\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "tag_data = pad_sequences(sequences, maxlen= None, padding= 'post' )\n",
        "word_index = tokenizer.word_index\n",
        "print('Found {} unique tokens'.format(len(word_index)))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 989 unique tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9c6tyI7mXJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f09f967-23b9-45bb-92ff-fd8f860607d5"
      },
      "source": [
        "tag_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4165, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-2NLkJSSwWI"
      },
      "source": [
        "Now, to get the vector for every text in the name column by averaging the vector for every word in the name. \n",
        "\n",
        "docs_vectors = pd.DataFrame() - An empty dataframe is created \n",
        "\n",
        "For every document in dataframe it will create a temporary dataframe(temp) and every word in document will now be in a list (words).\n",
        "\n",
        "Then for every word in list (words), it will create its embedding and stored in variable word2vec. Further a Pandas Series will be formed and appended in temporary dataframe (temp) for every word in the document.\n",
        "\n",
        " **Now for every word in the document, their respective mean will be taken for every dimension. Let's say for example, if a document contains 5 words. Initially, every word will be represented by 300 vectors. After taking mean of all those dimension in every vector space, that document will be represented by the mean of all words in respective dimension**\n",
        "\n",
        "At last all the 4165 documents present in the corpus will be represented by the vector mean of all the words present in each document as shown in the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_STSBgVflyY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "dd0ffcd0-b12d-44e1-9883-b5906c3a4c7c"
      },
      "source": [
        "docs_vectors = pd.DataFrame()\n",
        "for doc in df1.clean_name:\n",
        "    temp = pd.DataFrame()\n",
        "    words = doc.split(\" \")\n",
        "    for word in words:\n",
        "        try:\n",
        "            word2vec = embeddings[word]\n",
        "            temp = temp.append(pd.Series(word2vec), ignore_index = True)\n",
        "        except:\n",
        "            pass\n",
        "    doc_vector = temp.mean()\n",
        "    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True)\n",
        "docs_vectors.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.023206</td>\n",
              "      <td>-0.014844</td>\n",
              "      <td>0.023730</td>\n",
              "      <td>-0.079687</td>\n",
              "      <td>0.128202</td>\n",
              "      <td>-0.121924</td>\n",
              "      <td>0.220996</td>\n",
              "      <td>-0.153320</td>\n",
              "      <td>0.115802</td>\n",
              "      <td>0.178967</td>\n",
              "      <td>-0.199805</td>\n",
              "      <td>-0.159375</td>\n",
              "      <td>-0.054883</td>\n",
              "      <td>0.038428</td>\n",
              "      <td>-0.085840</td>\n",
              "      <td>-0.002661</td>\n",
              "      <td>0.063770</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.065186</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.029584</td>\n",
              "      <td>-0.018768</td>\n",
              "      <td>0.031152</td>\n",
              "      <td>-0.015283</td>\n",
              "      <td>0.059790</td>\n",
              "      <td>-0.098699</td>\n",
              "      <td>-0.174023</td>\n",
              "      <td>0.126123</td>\n",
              "      <td>-0.161572</td>\n",
              "      <td>-0.090576</td>\n",
              "      <td>0.066528</td>\n",
              "      <td>0.198242</td>\n",
              "      <td>0.120215</td>\n",
              "      <td>0.061011</td>\n",
              "      <td>-0.099609</td>\n",
              "      <td>-0.133301</td>\n",
              "      <td>0.171582</td>\n",
              "      <td>0.076617</td>\n",
              "      <td>-0.074365</td>\n",
              "      <td>0.029932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.147412</td>\n",
              "      <td>0.148413</td>\n",
              "      <td>-0.011719</td>\n",
              "      <td>-0.096973</td>\n",
              "      <td>0.015845</td>\n",
              "      <td>0.015805</td>\n",
              "      <td>-0.022998</td>\n",
              "      <td>0.017529</td>\n",
              "      <td>-0.218945</td>\n",
              "      <td>-0.018994</td>\n",
              "      <td>-0.059521</td>\n",
              "      <td>0.108691</td>\n",
              "      <td>-0.103003</td>\n",
              "      <td>0.073486</td>\n",
              "      <td>0.213867</td>\n",
              "      <td>-0.101947</td>\n",
              "      <td>-0.030674</td>\n",
              "      <td>-0.080008</td>\n",
              "      <td>-0.015283</td>\n",
              "      <td>0.139453</td>\n",
              "      <td>-0.129224</td>\n",
              "      <td>0.103589</td>\n",
              "      <td>-0.008594</td>\n",
              "      <td>-0.063904</td>\n",
              "      <td>0.071570</td>\n",
              "      <td>-0.094116</td>\n",
              "      <td>0.054346</td>\n",
              "      <td>0.023486</td>\n",
              "      <td>0.041138</td>\n",
              "      <td>0.046777</td>\n",
              "      <td>-0.022461</td>\n",
              "      <td>-0.050049</td>\n",
              "      <td>-0.153320</td>\n",
              "      <td>0.108447</td>\n",
              "      <td>0.087744</td>\n",
              "      <td>-0.094727</td>\n",
              "      <td>0.120126</td>\n",
              "      <td>-0.034898</td>\n",
              "      <td>-0.032501</td>\n",
              "      <td>0.105811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.013452</td>\n",
              "      <td>0.006641</td>\n",
              "      <td>-0.076758</td>\n",
              "      <td>-0.010156</td>\n",
              "      <td>0.085868</td>\n",
              "      <td>-0.134351</td>\n",
              "      <td>0.061475</td>\n",
              "      <td>-0.233789</td>\n",
              "      <td>-0.013867</td>\n",
              "      <td>0.223633</td>\n",
              "      <td>-0.145898</td>\n",
              "      <td>-0.095020</td>\n",
              "      <td>-0.124597</td>\n",
              "      <td>0.141821</td>\n",
              "      <td>-0.085547</td>\n",
              "      <td>0.038330</td>\n",
              "      <td>-0.126758</td>\n",
              "      <td>0.181665</td>\n",
              "      <td>-0.059277</td>\n",
              "      <td>-0.161719</td>\n",
              "      <td>-0.024512</td>\n",
              "      <td>0.036920</td>\n",
              "      <td>0.096191</td>\n",
              "      <td>0.037549</td>\n",
              "      <td>-0.086914</td>\n",
              "      <td>-0.095337</td>\n",
              "      <td>-0.144696</td>\n",
              "      <td>0.113037</td>\n",
              "      <td>-0.060596</td>\n",
              "      <td>-0.177246</td>\n",
              "      <td>0.086230</td>\n",
              "      <td>0.226172</td>\n",
              "      <td>0.099805</td>\n",
              "      <td>0.093701</td>\n",
              "      <td>-0.070093</td>\n",
              "      <td>0.005371</td>\n",
              "      <td>0.011499</td>\n",
              "      <td>0.085699</td>\n",
              "      <td>-0.034993</td>\n",
              "      <td>0.108789</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137891</td>\n",
              "      <td>0.168799</td>\n",
              "      <td>-0.053857</td>\n",
              "      <td>-0.087842</td>\n",
              "      <td>0.073486</td>\n",
              "      <td>0.075391</td>\n",
              "      <td>0.010413</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>-0.103027</td>\n",
              "      <td>-0.122693</td>\n",
              "      <td>-0.064795</td>\n",
              "      <td>0.139258</td>\n",
              "      <td>-0.022827</td>\n",
              "      <td>0.121613</td>\n",
              "      <td>0.172559</td>\n",
              "      <td>-0.137231</td>\n",
              "      <td>-0.100439</td>\n",
              "      <td>-0.104214</td>\n",
              "      <td>-0.006738</td>\n",
              "      <td>0.293945</td>\n",
              "      <td>-0.048437</td>\n",
              "      <td>0.127734</td>\n",
              "      <td>0.283398</td>\n",
              "      <td>0.010498</td>\n",
              "      <td>0.073926</td>\n",
              "      <td>-0.095825</td>\n",
              "      <td>-0.036523</td>\n",
              "      <td>0.129370</td>\n",
              "      <td>0.038586</td>\n",
              "      <td>0.021484</td>\n",
              "      <td>-0.115479</td>\n",
              "      <td>-0.049414</td>\n",
              "      <td>-0.151367</td>\n",
              "      <td>0.171240</td>\n",
              "      <td>0.161182</td>\n",
              "      <td>-0.135059</td>\n",
              "      <td>0.213574</td>\n",
              "      <td>0.054834</td>\n",
              "      <td>0.113568</td>\n",
              "      <td>0.164990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.047526</td>\n",
              "      <td>0.028280</td>\n",
              "      <td>-0.146606</td>\n",
              "      <td>0.039215</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>-0.090535</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>-0.284668</td>\n",
              "      <td>-0.000753</td>\n",
              "      <td>0.117635</td>\n",
              "      <td>-0.152649</td>\n",
              "      <td>-0.105367</td>\n",
              "      <td>-0.082113</td>\n",
              "      <td>0.037760</td>\n",
              "      <td>-0.200114</td>\n",
              "      <td>0.065336</td>\n",
              "      <td>-0.058838</td>\n",
              "      <td>0.124939</td>\n",
              "      <td>-0.031148</td>\n",
              "      <td>-0.147298</td>\n",
              "      <td>0.004496</td>\n",
              "      <td>-0.018895</td>\n",
              "      <td>0.026774</td>\n",
              "      <td>0.006124</td>\n",
              "      <td>-0.010539</td>\n",
              "      <td>0.005086</td>\n",
              "      <td>-0.117442</td>\n",
              "      <td>0.110769</td>\n",
              "      <td>-0.054565</td>\n",
              "      <td>-0.181905</td>\n",
              "      <td>0.027484</td>\n",
              "      <td>0.149251</td>\n",
              "      <td>0.056000</td>\n",
              "      <td>0.074890</td>\n",
              "      <td>-0.050690</td>\n",
              "      <td>-0.075104</td>\n",
              "      <td>0.027222</td>\n",
              "      <td>-0.031128</td>\n",
              "      <td>-0.122559</td>\n",
              "      <td>0.123372</td>\n",
              "      <td>...</td>\n",
              "      <td>0.211100</td>\n",
              "      <td>0.146606</td>\n",
              "      <td>-0.043254</td>\n",
              "      <td>-0.140340</td>\n",
              "      <td>0.100759</td>\n",
              "      <td>0.052572</td>\n",
              "      <td>-0.098022</td>\n",
              "      <td>-0.126851</td>\n",
              "      <td>-0.021729</td>\n",
              "      <td>-0.160706</td>\n",
              "      <td>-0.093831</td>\n",
              "      <td>0.167562</td>\n",
              "      <td>-0.068461</td>\n",
              "      <td>0.057210</td>\n",
              "      <td>0.242188</td>\n",
              "      <td>-0.208150</td>\n",
              "      <td>-0.079336</td>\n",
              "      <td>-0.107859</td>\n",
              "      <td>-0.049438</td>\n",
              "      <td>0.343424</td>\n",
              "      <td>-0.085490</td>\n",
              "      <td>0.080037</td>\n",
              "      <td>0.158896</td>\n",
              "      <td>-0.035400</td>\n",
              "      <td>0.011027</td>\n",
              "      <td>-0.111979</td>\n",
              "      <td>-0.070150</td>\n",
              "      <td>0.116781</td>\n",
              "      <td>0.007078</td>\n",
              "      <td>-0.025798</td>\n",
              "      <td>-0.078573</td>\n",
              "      <td>-0.049235</td>\n",
              "      <td>-0.061968</td>\n",
              "      <td>0.152679</td>\n",
              "      <td>0.087118</td>\n",
              "      <td>-0.159668</td>\n",
              "      <td>0.211568</td>\n",
              "      <td>0.036499</td>\n",
              "      <td>0.126623</td>\n",
              "      <td>0.142863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.051229</td>\n",
              "      <td>0.070624</td>\n",
              "      <td>-0.104913</td>\n",
              "      <td>0.010830</td>\n",
              "      <td>0.027983</td>\n",
              "      <td>-0.097805</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>-0.200684</td>\n",
              "      <td>-0.013455</td>\n",
              "      <td>0.131904</td>\n",
              "      <td>-0.046997</td>\n",
              "      <td>-0.120511</td>\n",
              "      <td>-0.030321</td>\n",
              "      <td>0.056017</td>\n",
              "      <td>-0.163954</td>\n",
              "      <td>0.030409</td>\n",
              "      <td>-0.061849</td>\n",
              "      <td>0.107435</td>\n",
              "      <td>-0.025594</td>\n",
              "      <td>-0.050388</td>\n",
              "      <td>-0.066271</td>\n",
              "      <td>0.053999</td>\n",
              "      <td>0.053182</td>\n",
              "      <td>-0.056301</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>-0.040371</td>\n",
              "      <td>-0.129598</td>\n",
              "      <td>0.088901</td>\n",
              "      <td>0.004374</td>\n",
              "      <td>-0.171238</td>\n",
              "      <td>-0.053753</td>\n",
              "      <td>0.130208</td>\n",
              "      <td>0.022196</td>\n",
              "      <td>0.118842</td>\n",
              "      <td>-0.141269</td>\n",
              "      <td>0.012268</td>\n",
              "      <td>0.030938</td>\n",
              "      <td>0.051817</td>\n",
              "      <td>-0.109836</td>\n",
              "      <td>0.071398</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074544</td>\n",
              "      <td>0.107313</td>\n",
              "      <td>-0.073893</td>\n",
              "      <td>-0.095405</td>\n",
              "      <td>0.069004</td>\n",
              "      <td>0.085286</td>\n",
              "      <td>-0.018246</td>\n",
              "      <td>-0.069478</td>\n",
              "      <td>-0.090698</td>\n",
              "      <td>-0.005710</td>\n",
              "      <td>-0.061452</td>\n",
              "      <td>0.099202</td>\n",
              "      <td>-0.022637</td>\n",
              "      <td>-0.012587</td>\n",
              "      <td>0.189182</td>\n",
              "      <td>-0.023695</td>\n",
              "      <td>-0.090217</td>\n",
              "      <td>-0.075916</td>\n",
              "      <td>-0.059068</td>\n",
              "      <td>0.232259</td>\n",
              "      <td>0.020277</td>\n",
              "      <td>0.064996</td>\n",
              "      <td>0.136313</td>\n",
              "      <td>-0.056803</td>\n",
              "      <td>0.000570</td>\n",
              "      <td>-0.109407</td>\n",
              "      <td>-0.072866</td>\n",
              "      <td>0.161296</td>\n",
              "      <td>0.019150</td>\n",
              "      <td>0.020020</td>\n",
              "      <td>-0.158827</td>\n",
              "      <td>-0.087891</td>\n",
              "      <td>-0.033206</td>\n",
              "      <td>0.088657</td>\n",
              "      <td>0.081651</td>\n",
              "      <td>-0.095662</td>\n",
              "      <td>0.112101</td>\n",
              "      <td>0.007894</td>\n",
              "      <td>0.062836</td>\n",
              "      <td>0.150689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.018276</td>\n",
              "      <td>0.010498</td>\n",
              "      <td>-0.147879</td>\n",
              "      <td>0.052804</td>\n",
              "      <td>0.138288</td>\n",
              "      <td>-0.018781</td>\n",
              "      <td>0.031054</td>\n",
              "      <td>-0.315430</td>\n",
              "      <td>-0.045410</td>\n",
              "      <td>0.120745</td>\n",
              "      <td>-0.179513</td>\n",
              "      <td>-0.179967</td>\n",
              "      <td>-0.093192</td>\n",
              "      <td>0.026193</td>\n",
              "      <td>-0.209303</td>\n",
              "      <td>0.115287</td>\n",
              "      <td>-0.071568</td>\n",
              "      <td>0.093977</td>\n",
              "      <td>-0.021781</td>\n",
              "      <td>-0.164202</td>\n",
              "      <td>-0.035788</td>\n",
              "      <td>-0.024288</td>\n",
              "      <td>0.022740</td>\n",
              "      <td>0.018450</td>\n",
              "      <td>-0.030430</td>\n",
              "      <td>-0.000457</td>\n",
              "      <td>-0.109811</td>\n",
              "      <td>0.114755</td>\n",
              "      <td>-0.034954</td>\n",
              "      <td>-0.215594</td>\n",
              "      <td>0.029705</td>\n",
              "      <td>0.122035</td>\n",
              "      <td>0.038749</td>\n",
              "      <td>0.123797</td>\n",
              "      <td>-0.126107</td>\n",
              "      <td>-0.003592</td>\n",
              "      <td>0.082132</td>\n",
              "      <td>0.073312</td>\n",
              "      <td>-0.143520</td>\n",
              "      <td>0.107073</td>\n",
              "      <td>...</td>\n",
              "      <td>0.212542</td>\n",
              "      <td>0.149711</td>\n",
              "      <td>-0.092939</td>\n",
              "      <td>-0.143938</td>\n",
              "      <td>0.091692</td>\n",
              "      <td>0.053711</td>\n",
              "      <td>-0.065116</td>\n",
              "      <td>-0.057408</td>\n",
              "      <td>-0.065151</td>\n",
              "      <td>-0.138157</td>\n",
              "      <td>-0.109427</td>\n",
              "      <td>0.197056</td>\n",
              "      <td>-0.114310</td>\n",
              "      <td>0.117815</td>\n",
              "      <td>0.178362</td>\n",
              "      <td>-0.142905</td>\n",
              "      <td>-0.001979</td>\n",
              "      <td>-0.069449</td>\n",
              "      <td>-0.060826</td>\n",
              "      <td>0.278878</td>\n",
              "      <td>-0.101772</td>\n",
              "      <td>0.026167</td>\n",
              "      <td>0.188234</td>\n",
              "      <td>-0.024091</td>\n",
              "      <td>0.014195</td>\n",
              "      <td>-0.095930</td>\n",
              "      <td>-0.079799</td>\n",
              "      <td>0.089739</td>\n",
              "      <td>0.037456</td>\n",
              "      <td>0.051758</td>\n",
              "      <td>-0.149536</td>\n",
              "      <td>0.045027</td>\n",
              "      <td>-0.120245</td>\n",
              "      <td>0.161874</td>\n",
              "      <td>0.048410</td>\n",
              "      <td>-0.177595</td>\n",
              "      <td>0.224435</td>\n",
              "      <td>0.045163</td>\n",
              "      <td>0.106432</td>\n",
              "      <td>0.165213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       297       298       299\n",
              "0 -0.023206 -0.014844  0.023730  ... -0.034898 -0.032501  0.105811\n",
              "1 -0.013452  0.006641 -0.076758  ...  0.054834  0.113568  0.164990\n",
              "2 -0.047526  0.028280 -0.146606  ...  0.036499  0.126623  0.142863\n",
              "3 -0.051229  0.070624 -0.104913  ...  0.007894  0.062836  0.150689\n",
              "4 -0.018276  0.010498 -0.147879  ...  0.045163  0.106432  0.165213\n",
              "\n",
              "[5 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXZobw6MPrdo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c3d50b0-a132-44e9-ef69-48c339469693"
      },
      "source": [
        "docs_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4165, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVNzQDHMZYq1"
      },
      "source": [
        "Shape of document vector is same as that of dataframe (4165) with 300 columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4mDgpSyI1zH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P96VBUYEZrz0"
      },
      "source": [
        "# Image Embeddings Input Model (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynq6WMnn1ZPx"
      },
      "source": [
        "Brief introduction about VGG16 and Transfer Learning: \n",
        "Transfer learning make use of the knowledge gained while solving one problem and applying it to a different but related problem. When we train any neural network on a large dataset, we train all the parameters of the neural network and therefore the model is learned. Hence, rather training the entire model, we just to add layer according to our model, and fine-tune saving time and computation cost  \n",
        "\n",
        "VGG-16 is a convolutional neural network that is 16 layers deep. We can load a pretrained version of the network trained on more than a million images from the ImageNet database. The pretrained network can classify images into 1000 object categories, such as wallet, jackets, etc. As a result, the network has learned rich feature representations for a wide range of images. The network has an image input size of 224-by-224. We can classify new images using the VGG-16 network.\n",
        "\n",
        "Most unique thing about VGG16 is that instead of having a large number of hyper-parameter they focused on having convolution layers of 3x3 filter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2. It follows this arrangement of convolution and max pool layers consistently throughout the whole architecture. In the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has 16 layers that have weights. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GZtoOsFL2Eh"
      },
      "source": [
        "One way to do this is to not include the fully-connected layers at the top of the network.\n",
        "Then add new fully-connect layers with random initialization, with the correct num of output.\n",
        "\n",
        "The convolutional layers will be initialized with weights based on a training on ImageNet dataset.\n",
        "Generally, we can say that the convolutional layers work as features extractors.\n",
        "\n",
        "But you to train train the whole network for your 8 classes. This training will train the new fully-connected layers and fine-train the convolutional layers. (you can freeze the convolutional layers, to keep the same features extractors)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGD81ovVzoBa"
      },
      "source": [
        "Hyperparameter tuning meaning : weights = \"imagenet\" (pre-training on ImageNet), \n",
        "\n",
        "include_top = False (don't include the fully-connected layers at the top of the network.)\n",
        "input_shape = (optional shape tuple, only to be specified\n",
        "            if \"include_top\" is False). This means shape of the image will be as given, here in this case (64,64,3) matrix.\n",
        "\n",
        "x = layers.Flatten()(vgg16)\n",
        "Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.\n",
        "\n",
        "x = layers.Dense(4, activation='softmax')(x): This is the final layer with 4 neurons. Activation function is softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzJjqw1fl3_"
      },
      "source": [
        "image_input = Input(shape=(64, 64, 3), name='image')\n",
        "vgg16 = VGG16(weights= \"imagenet\",\n",
        "                  include_top=False,\n",
        "                  input_shape=(64, 64, 3))(image_input)\n",
        "x = layers.Flatten()(vgg16) \n",
        "x = layers.Dense(4, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3XjWSAdJYtf"
      },
      "source": [
        "# Part 2 \n",
        "\n",
        "Image Tower Model (10 points) \n",
        "\n",
        "Text Tower Model (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieWUuJfTV9GX"
      },
      "source": [
        "**Keras offers an Embedding layer that can be used for neural networks on text data.**\n",
        "\n",
        "It requires that the input data be integer encoded, so that each word is represented by a unique integer. It is a flexible layer that can be used to load a pre-trained word embedding model, a type of transfer learning.\n",
        "\n",
        "The first argument (4165) is the number of distinct words in the training set. The second argument (300) indicates the size of the embedding vectors.\n",
        "\n",
        "The output of the Embedding layer is a 2D vector with one embedding for each word in the input sequence of words (input document).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWcPQzrqfl6O"
      },
      "source": [
        "tag_input = Input(shape=(None,), dtype='int32', name='tag')\n",
        "embedded_tag = layers.Embedding(input_dim= 4165, output_dim= 300)(tag_input)\n",
        "encoded_tag = layers.LSTM(512)(embedded_tag)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZS3sEERh6UE"
      },
      "source": [
        "Recurrent Neural Network are good at working with sequence data like text, however they have inherent weakness of short term memory. To overcome, this weakness more evolved version of LSTM are used.\n",
        "\n",
        "No. of units defined is 512 which means 512 features will input for each time step. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiU6iTVilNej"
      },
      "source": [
        "Now both image layers (x) and text layer are joined. At the final layer , dense that is fully connected layers are also connected with 4 softmax activation functions with the previous concatenated layers. (4 because there are 4 different labels)\n",
        "\n",
        "So my model is image_imput , tag_input and output layer\n",
        "\n",
        "After that compiling is done. Compile defines the loss function, the optimizer and the metrics. \n",
        "\n",
        "Optimizers are algorithms or methods used to change the attributes of neural network such as weights and learning rate in order to reduce the losses. rmsprop uses a moving average of squared gradients to normalize the gradient itself. That has an effect of balancing the step size — decrease the step for large gradient to avoid exploding, and increase the step for small gradient to avoid vanishing.\n",
        "\n",
        "Cross-entropy is the default loss function to use for multi-class classification problems.\n",
        "\n",
        "A metric is a function that is used to judge the performance of model. It calculates the accuracy of a single (y_true, y_pred) pair by checking if the predicted class is the same as the true class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC6HKOw3KEEH"
      },
      "source": [
        "# Class Level Similarity (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQGX2YJufl9D"
      },
      "source": [
        "concatenated = layers.concatenate([x, encoded_tag], axis=-1)\n",
        "output = layers.Dense(4, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([image_input, tag_input], output)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmMQjZXWfmCa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "2b517ae6-4ad9-4426-ee9a-8017c66cc8b1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image (InputLayer)              (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vgg16 (Model)                   (None, 2, 2, 512)    14714688    image[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tag (InputLayer)                (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 2048)         0           vgg16[1][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 300)    1249500     tag[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            8196        flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 512)          1665024     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 516)          0           dense_4[0][0]                    \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4)            2068        concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 17,639,476\n",
            "Trainable params: 17,639,476\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfBn1PBqpWS_"
      },
      "source": [
        "Freezing VGG16 convolutional base and word2vec word embedding layer from training as I don't need to retrain these layer as they are pre trained\n",
        "\n",
        "Defining the weights of embedding layers as that of docs_vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h76H90oKfl_t"
      },
      "source": [
        "model.layers[1].trainable = False \n",
        "model.layers[4].set_weights([docs_vectors])\n",
        "model.layers[4].trainable = False "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIoDRfoLflmV"
      },
      "source": [
        "dim = (64, 64) # This will take pixel image in 150,150 shape\n",
        "X_image_train = []\n",
        "X_tag_train = tag_data\n",
        "y_train = []\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu8S8yGer448"
      },
      "source": [
        "Creating list of paths of images of each labels \"necklace\", \"coat-long\", \"casual jackets\" and \"knitwear\", separately, then reading their pixel form and resizing it into 64X64 format and appending to their respective X_image_train_\"label\" list \n",
        "\n",
        "Another list for each labels is created describing their label in numeric form, that is (0,1,2 and 3) respectively. Categorical labels are converted to numeric labels because the machine understand numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38X9cZ154VQu"
      },
      "source": [
        "image_path = '/content/gdrive/My Drive/greendeck/train/coats_long/'\n",
        "coats_long = []\n",
        "y_coats_long = []\n",
        "X_image_train_coat = []\n",
        "for image in os.listdir(image_path):\n",
        "  coats_long.append(image)\n",
        "  y_coats_long.append(0)\n",
        "for i in range(len(coats_long)):\n",
        "  ima = image_path+(coats_long[i])\n",
        "  im = plt.imread(ima)\n",
        "  im_resized = cv2.resize(im,(64,64),  interpolation = cv2.INTER_AREA)\n",
        "  X_image_train_coat.append(im_resized)\n",
        "\n",
        "image_path = '/content/gdrive/My Drive/greendeck/train/fine jewelry_necklaces/'\n",
        "neck = []\n",
        "y_neck = []\n",
        "X_image_train_neck = []\n",
        "for image in os.listdir(image_path):\n",
        "  neck.append(image)\n",
        "  y_neck.append(1)\n",
        "\n",
        "for i in range(len(neck)):\n",
        "  ima = image_path+(neck[i])\n",
        "  im = plt.imread(ima)\n",
        "  im_resized = cv2.resize(im,(64,64),  interpolation = cv2.INTER_AREA)\n",
        "  X_image_train_neck.append(im_resized)\n",
        "\n",
        "image_path = '/content/gdrive/My Drive/greendeck/train/jackets_casual jackets/'\n",
        "jack = []\n",
        "y_jack = []\n",
        "X_image_train_jack = []\n",
        "for image in os.listdir(image_path):\n",
        "  jack.append(image)\n",
        "  y_jack.append(2)\n",
        "\n",
        "for i in range(len(jack)):\n",
        "  ima = image_path+(jack[i])\n",
        "  im = plt.imread(ima)\n",
        "  im_resized = cv2.resize(im,(64,64),  interpolation = cv2.INTER_AREA)\n",
        "  X_image_train_jack.append(im_resized)\n",
        "\n",
        "image_path = '/content/gdrive/My Drive/greendeck/train/knitwear_fine knit/'\n",
        "knit = []\n",
        "y_knit = []\n",
        "X_image_train_knit = []\n",
        "for image in os.listdir(image_path):\n",
        "  knit.append(image)\n",
        "  y_knit.append(3)\n",
        "\n",
        "for i in range(len(knit)):\n",
        "  ima = image_path+(knit[i])\n",
        "  im = plt.imread(ima)\n",
        "  im_resized = cv2.resize(im,(64,64),  interpolation = cv2.INTER_AREA)\n",
        "  X_image_train_knit.append(im_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iGv53wqthKs"
      },
      "source": [
        "All the pixel arrays is now extended finally to \"X_image_train_final\" list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gFryNwYtqRl"
      },
      "source": [
        "X_image_train_final = []\n",
        "X_image_train_final.extend(X_image_train_coat)\n",
        "X_image_train_final.extend(X_image_train_neck)\n",
        "X_image_train_final.extend(X_image_train_jack)\n",
        "X_image_train_final.extend(X_image_train_knit)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV9A-haAuKJD"
      },
      "source": [
        "All the numeric labels is now extended to \"y_train_final\" list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vh5tmar2bBe"
      },
      "source": [
        "y_train_final = []\n",
        "y_train_final.extend(y_coats_long)\n",
        "y_train_final.extend(y_neck)\n",
        "y_train_final.extend(y_jack)\n",
        "y_train_final.extend(y_knit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTTZNzvqF0ql"
      },
      "source": [
        "Converting from list to array form of images, tags and labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5252_j5k2aQ7"
      },
      "source": [
        "X_image_train = np.array(X_image_train_final)\n",
        "X_tag_train   = np.array(tag_data)\n",
        "y_train       = np.array(y_train_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKLO1FJ0GP0j"
      },
      "source": [
        "Shuffling them to avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOcFbLU6jZdr"
      },
      "source": [
        "perm = np.arange(y_train.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "X_image_train = X_image_train[perm]\n",
        "X_tag_train   = X_tag_train[perm]\n",
        "y_train       = y_train[perm]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGeGctrRKgtP"
      },
      "source": [
        "Getting the shapes of images , tag and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imu9yz8GjZhp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f175de66-6215-4bcb-cbe9-6d12239c0574"
      },
      "source": [
        "X_image_train.shape,  X_tag_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3123, 64, 64, 3), (3123, 14), (3123,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN51vmp-KpG6"
      },
      "source": [
        "Fitting the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Vf616zjZnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d131559b-dfb2-48b9-b390-0c8361e31f71"
      },
      "source": [
        "model.fit([X_image_train,X_tag_train], y_train, epochs=5, batch_size=150) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3123/3123 [==============================] - 531s 170ms/step - loss: 0.7196 - accuracy: 0.6481\n",
            "Epoch 2/5\n",
            "3123/3123 [==============================] - 525s 168ms/step - loss: 0.6693 - accuracy: 0.6612\n",
            "Epoch 3/5\n",
            "3123/3123 [==============================] - 524s 168ms/step - loss: 0.7174 - accuracy: 0.6366\n",
            "Epoch 4/5\n",
            "3123/3123 [==============================] - 525s 168ms/step - loss: 0.6401 - accuracy: 0.6647\n",
            "Epoch 5/5\n",
            "3123/3123 [==============================] - 523s 168ms/step - loss: 0.6304 - accuracy: 0.6753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5ef0bc7ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjE8qjthMNcF"
      },
      "source": [
        "Uploading test files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X3sO4wyqRqP",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "0a1966ee-4e06-4b63-a45a-92ae477644ad"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-98834305-3bb8-48f7-b92a-253755aea575\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-98834305-3bb8-48f7-b92a-253755aea575\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I23L-xtyMlRi"
      },
      "source": [
        "Reading test file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL_sVmzuqRo1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "768b924f-96c1-4e9a-cd79-2a47cd7b029b"
      },
      "source": [
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image</th>\n",
              "      <th>name</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34759</td>\n",
              "      <td>5db81220d5424ee1f3353536_2.jpg</td>\n",
              "      <td>SAINT LAURENT  Printed textured-leather cardho...</td>\n",
              "      <td>accessories&lt;wallets&lt;cardholders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35999</td>\n",
              "      <td>5da81ce17d3a9baa211f83cd_2.jpg</td>\n",
              "      <td>Balenciaga  Everyday glittered leather cardhol...</td>\n",
              "      <td>accessories&lt;wallets&lt;cardholders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36000</td>\n",
              "      <td>5da81c817861c2af6a5a84ed_2.jpg</td>\n",
              "      <td>Balenciaga  Ville printed textured-leather car...</td>\n",
              "      <td>accessories&lt;wallets&lt;cardholders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36001</td>\n",
              "      <td>5da8192d6504fb65cea6ffc3_2.jpg</td>\n",
              "      <td>Balenciaga  Ville printed textured-leather car...</td>\n",
              "      <td>accessories&lt;wallets&lt;cardholders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36217</td>\n",
              "      <td>5da81a447d3a9baa211f7e68_2.jpg</td>\n",
              "      <td>Burberry  Printed textured-leather cardholder</td>\n",
              "      <td>accessories&lt;wallets&lt;cardholders</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                          classes\n",
              "0       34759  ...  accessories<wallets<cardholders\n",
              "1       35999  ...  accessories<wallets<cardholders\n",
              "2       36000  ...  accessories<wallets<cardholders\n",
              "3       36001  ...  accessories<wallets<cardholders\n",
              "4       36217  ...  accessories<wallets<cardholders\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A0_NR4a7GmR"
      },
      "source": [
        "Getting the dataframe as obtained in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-5jZylfJi4r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "04cd04be-7234-4277-b47f-87a4b9b57a19"
      },
      "source": [
        "test.set_index(['classes'], inplace = True)\n",
        "tdf = test.loc[['clothing<coats<long','jewelry and watches<fine jewelry<necklaces','clothing<jackets<casual jackets','clothing<knitwear<fine knit']]\n",
        "tdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>classes</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>clothing&lt;coats&lt;long</th>\n",
              "      <td>55912</td>\n",
              "      <td>5da8192d6504fb65cea6ffb5_4.jpg</td>\n",
              "      <td>Max Mara  The Cube hooded quilted shell down c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;coats&lt;long</th>\n",
              "      <td>55952</td>\n",
              "      <td>5da81a487d3a9baa211f7f10_4.jpg</td>\n",
              "      <td>GANNI  + 66 North Askja hooded striped quilted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;coats&lt;long</th>\n",
              "      <td>56049</td>\n",
              "      <td>5db81047d5424ee1f3352825_4.jpg</td>\n",
              "      <td>Stand Studio  Taylor oversized faux shearling ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;coats&lt;long</th>\n",
              "      <td>56137</td>\n",
              "      <td>5da8221a6504fb65da005a89_4.jpg</td>\n",
              "      <td>Tibi  Oversized embellished wool-blend coat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;coats&lt;long</th>\n",
              "      <td>56201</td>\n",
              "      <td>5da82229b25b035d1d17c06f_4.jpg</td>\n",
              "      <td>Carolina Herrera  Oversized wool and cashmere-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;knitwear&lt;fine knit</th>\n",
              "      <td>64963</td>\n",
              "      <td>5da81eff7f3e301b4504b930_6.jpg</td>\n",
              "      <td>Max Mara  Wool turtleneck sweater</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;knitwear&lt;fine knit</th>\n",
              "      <td>65042</td>\n",
              "      <td>5da8190b6504fb65cb2615d7_6.jpg</td>\n",
              "      <td>Akris  Ribbed cashmere and mulberry silk-blend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;knitwear&lt;fine knit</th>\n",
              "      <td>65274</td>\n",
              "      <td>5da820956504fb65da003dc2_6.jpg</td>\n",
              "      <td>Salvatore Ferragamo  Button-detailed ribbed wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;knitwear&lt;fine knit</th>\n",
              "      <td>65284</td>\n",
              "      <td>5da8219a6504fb65da0050bd_6.jpg</td>\n",
              "      <td>Off-White  Asymmetric paneled ribbed-knit turt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clothing&lt;knitwear&lt;fine knit</th>\n",
              "      <td>65378</td>\n",
              "      <td>5da81a487d3a9baa211f7eda_6.jpg</td>\n",
              "      <td>LESET  Lori belted brushed stretch-jersey card...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1042 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Unnamed: 0  ...                                               name\n",
              "classes                                  ...                                                   \n",
              "clothing<coats<long               55912  ...  Max Mara  The Cube hooded quilted shell down c...\n",
              "clothing<coats<long               55952  ...  GANNI  + 66 North Askja hooded striped quilted...\n",
              "clothing<coats<long               56049  ...  Stand Studio  Taylor oversized faux shearling ...\n",
              "clothing<coats<long               56137  ...      Tibi  Oversized embellished wool-blend coat  \n",
              "clothing<coats<long               56201  ...  Carolina Herrera  Oversized wool and cashmere-...\n",
              "...                                 ...  ...                                                ...\n",
              "clothing<knitwear<fine knit       64963  ...                Max Mara  Wool turtleneck sweater  \n",
              "clothing<knitwear<fine knit       65042  ...  Akris  Ribbed cashmere and mulberry silk-blend...\n",
              "clothing<knitwear<fine knit       65274  ...  Salvatore Ferragamo  Button-detailed ribbed wo...\n",
              "clothing<knitwear<fine knit       65284  ...  Off-White  Asymmetric paneled ribbed-knit turt...\n",
              "clothing<knitwear<fine knit       65378  ...  LESET  Lori belted brushed stretch-jersey card...\n",
              "\n",
              "[1042 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbTcL1YpL1ak"
      },
      "source": [
        "Creating path of image test file , reading image in its pixel form and then resizing it to 64X64 matrix form. Appending it to its respective X_image_test list. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyn9-RMkjZ1I"
      },
      "source": [
        "test_image_dir = '/content/drive/My Drive/greendeck/test/coats_long'\n",
        "dim = (64,64)\n",
        "X_image_test_coats = []\n",
        "for fname in listdir(test_image_dir):\n",
        "    fpath = os.path.join(test_image_dir, fname)\n",
        "    im = cv2.imread(fpath)\n",
        "    im_resized = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
        "    X_image_test_coats.append(im_resized)\n",
        "\n",
        "\n",
        "test_image_dir = '/content/drive/My Drive/greendeck/test/fine jewelry_necklaces'\n",
        "dim = (64,64)\n",
        "X_image_test_neck = []\n",
        "for fname in listdir(test_image_dir):\n",
        "    fpath = os.path.join(test_image_dir, fname)\n",
        "    im = cv2.imread(fpath)\n",
        "    im_resized = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
        "    X_image_test_neck.append(im_resized)\n",
        "\n",
        "test_image_dir = '/content/drive/My Drive/greendeck/test/jackets_casual jackets'\n",
        "dim = (64,64)\n",
        "X_image_test_jacket = []\n",
        "for fname in listdir(test_image_dir):\n",
        "    fpath = os.path.join(test_image_dir, fname)\n",
        "    im = cv2.imread(fpath)\n",
        "    im_resized = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
        "    X_image_test_jacket.append(im_resized)\n",
        "\n",
        "test_image_dir = '/content/drive/My Drive/greendeck/test/knitwear_fine knit'\n",
        "dim = (64,64)\n",
        "X_image_test_knit = []\n",
        "for fname in listdir(test_image_dir):\n",
        "    fpath = os.path.join(test_image_dir, fname)\n",
        "    im = cv2.imread(fpath)\n",
        "    im_resized = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
        "    X_image_test_knit.append(im_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19JoFKAit1R1"
      },
      "source": [
        "Adding images from every labels to a single list X_images_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVdImzi2r6To"
      },
      "source": [
        "X_image_test = []\n",
        "X_image_test.extend(X_image_test_coats)\n",
        "X_image_test.extend(X_image_test_neck)\n",
        "X_image_test.extend(X_image_test_jacket)\n",
        "X_image_test.extend(X_image_test_knit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKKUPXInMyxj"
      },
      "source": [
        "Tokenising its description , converting it to numeric sequences and padding it as done with the training tags.  However, the word index ( unique sequence number given to unique token is same for both train and test tags to avoid confusion)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ik4scdjaEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e295c63b-3207-4a43-af04-6f70f6e34463"
      },
      "source": [
        "tokenizer_test = Tokenizer()\n",
        "texts_test = []\n",
        "for tag_list in tdf.index:\n",
        "    texts_test.append(''.join(tag_list))\n",
        "\n",
        "tokenizer_test.fit_on_texts(texts)\n",
        "sequences = tokenizer_test.texts_to_sequences(texts_test)\n",
        "word_index_test = tokenizer_test.word_index\n",
        "print('Found {} unique tokens in test'.format(len(word_index_test)))\n",
        "tag_data_test = pad_sequences(sequences, maxlen= None, padding= 'post')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 989 unique tokens in test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfWE9t0zNIbr"
      },
      "source": [
        "Making an array of test_images and test_tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzVxHtHmqRdl"
      },
      "source": [
        "X_image_test = np.array(X_image_test)\n",
        "X_tag_test = np.array(tag_data_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOkjfWQKxFAE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f65d39e-27c0-4164-bb32-a8812884302c"
      },
      "source": [
        "X_image_test.shape, X_tag_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1042, 64, 64, 3), (1042, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3flpiH3NTcJ"
      },
      "source": [
        "Predicting for the image test image and test  tag "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m_xeBYcxFK6"
      },
      "source": [
        "result =model.predict([X_image_test,X_tag_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUDPWFZz8WWU"
      },
      "source": [
        "Predicting the image and its tags by a given input index. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e776odn_xFOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "026b4419-94fa-4754-88b0-a8458b880928"
      },
      "source": [
        "n = int(input())\n",
        "result[n].argmax()\n",
        "if result[n].argmax() == 0:\n",
        " plt.imshow(X_image_test[n])\n",
        "elif result[n].argmax() == 1:\n",
        "  plt.imshow(X_image_test[n])\n",
        "elif result[n].argmax() == 2:\n",
        " plt.imshow(X_image_test[n])\n",
        "elif result[n].argmax() == 3:\n",
        "  plt.imshow(X_image_test[n])\n",
        "\n",
        "print(\"Tags for the given image are: \")\n",
        "for i in X_tag_train[n]:\n",
        "  try:\n",
        "   print(list(word_index_test.keys())[list(word_index_test.values()).index(i)],end = \",\")\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "Tags for the given image are: \n",
            "gucci,oversized,floral,print,coated,cotton,drill,trench,coat,"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QJwGoubE457"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}